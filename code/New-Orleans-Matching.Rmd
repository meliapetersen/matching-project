---
title: "New-Orleans-matching"
author: "Jaesa Rogers"
date: "8/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F )
```

# Create New Orelans matches

```{r}
# need this installed to use
# genetic matching option in MatchIt
# install.packages("rgenoud")

# load package 
library( MatchIt )
library( here )
library( dplyr )
```

```{r}
#load LTDB data
d1 <- readRDS(here ( "data/data-rodeo/LTDB-2000.rds" ))
d2 <- readRDS(here ( "data/data-rodeo/LTDB-2010.rds" ))
md <- readRDS(here ( "data/data-rodeo/LTDB-META-DATA.rds" ))

#clean data 
d1 <- select( d1, - year )
d2 <- select( d2, - year )

d <- merge( d1, d2, by="tractid" )
d <- merge( d, md, by="tractid" )

#load NMTC data 
URL1 <- "https://raw.githubusercontent.com/DS4PS/cpp-528-spr-2020/master/labs/data/raw/NMTC/nmtc-sheet-01.csv"
nmtc <- read.csv( URL1, stringsAsFactors=F )

# remove anything not a number from the string
d$id2 <- gsub( "[^0-9]", "", d$tractid )

# fix IDs so they are match
d$id2 <- as.numeric( d$id2 )

# need to convert from currency to numeric
# current format: 
# head( nmtc$QLICI.Amount )
# [1] "$300,000.00 "   "$1,008,750.00 " "$977,000.00 "

# remove dollar sign and commas
nmtc$amount <- gsub( "[,$]", "", nmtc$QLICI.Amount )

# head(  nmtc$amount  )
# "300000.00 "  "1008750.00 " "977000.00 "

# convert characters to numeric 
nmtc$amount <- as.numeric( nmtc$amount ) %>% round(0)

# head(  nmtc$amount  )
# [1]  300000 1008750  977000

nmtc.dollars <- 
  nmtc %>% 
  filter( Origination.Year >= 2000 & Origination.Year <= 2010 ) %>%
  group_by( X2010.Census.Tract ) %>% 
  summarize( num.nmtc=n(), nmtc.total = sum( amount, na.rm=T ) )

d <- merge( d, nmtc.dollars, by.x="id2", by.y="X2010.Census.Tract", all.x=T )

# recode tracts that had no grants from NA to 0
d$num.nmtc[ is.na(d$num.nmtc) ] <- 0
d$nmtc.total[ is.na(d$nmtc.total) ] <- 0

#remove rural districts 
d <- filter( d, urban == "urban" )


```

### Create data frame for matching

```{r}
# create treatment variable
treatment <- ifelse(d$nmtc.total>0, 1, 0)

# add to dataframe

d$treatment <- treatment

```


```{r}
# match nmtc as treatment (census tracts that recieved nmtc funding vs those that didn't)
# and seek balance on other SES characteristics 

## immigrants, high school education, home ownership, pop density (cpp 528 lab), tenure in the neighborhood

df <- 
  d %>% 
  select( cbsa, tractid, treatment, rent00, hinc00, pnhwht12, pnhblk12, phisp12, 
              ppov12, punemp12,
              hinc12, hincb12, hincw12, 
              phs12, pcol12,
              pown12, mhmval12 ) %>% 
 filter( treatment %in% c( 1,0 ) ) %>% 
 mutate( Treated = as.numeric( treatment == 1 ), 
           Control =  as.numeric( treatment == 0 ))

# drop rows with missing values

nrow( df )
df2 <- na.omit( df )
nrow( df2 )


# "treated" group is white
# comparison set is minority communities
```


### matchit function 

### Genetic Search Method

Better method, but more computationally intensive. 

We use a smaller sample here, but to run with the full sample it may require running it overnight or on the supercomputing clusters. 


**NOTE** the long output printed while the algorithm runs. Add code chunk option

results 

```{r, results="hide", cache=TRUE}
# test genetic search method
# is time-intensive so test with a sample

# set seeds if you want to reproduce the 
# exact result in the future
set.seed( seed=1234 )

# create sample set for cities with high NMTC funding: New Orleans
df3 <- df2  %>%  filter(cbsa %in% c(35380, 20260))
           
# df3$cbsa.f <- factor(df3$cbsa)      
                 
table( df3$treatment )


m5 <- matchit( treatment ~ hinc12 + pcol12 + pnhwht12 + cbsa, 
               method="genetic", discard="both", reestimate=TRUE, 
               replace=FALSE, caliper=.25, data = df3 ) 

```

Report resulting fits:

```{r}
 
summary( m5 )   # replacement false with calipers 
```


Constructing the balanced sample: 




```{r}
# match matrix is the length of the original treated groups
# IDs are rows of the original dataset

matches <- data.frame( treatment.group.id=row.names( m5$match.matrix), 
                       control.group.id=m5$match.matrix )

head( matches, 34 )
```


```{r}
# compare quality of matches
# select id (row) of treated and id (row) of comparison,
# compare on model covariates:

# note the nice balance: 

df3[ c(10,334, 14, 331, 22, 198) , c("cbsa", "tractid", "hinc12", "pcol12", "pnhwht12", "treatment") ]


m5$nn

# all treated cases in dataset:
length( m5$match.matrix )

# treated cases that were matched: 
sum( ! is.na(m5$match.matrix) )
```

### Extract balanced dataset 

Keep only cases that were matched in previous steps 

```{r}
new.dat <- match.data( m5 )
dim( new.dat ) # 2 x number in matched treatment group
head( new.dat, 34 )
```



# Create New Orleans Map 

```{r}
library( geojsonio )   # read shapefiles
library( sp )          # work with shapefiles
library( sf )          # work with shapefiles - simple features format
library( mclust )      # cluster analysis 
library( tmap )        # theme maps
library( ggplot2 )     # graphing 
library( ggthemes )    # nice formats for ggplots
library( dplyr )       # data wrangling 
library( pander )      # formatting RMD tables
library( tidycensus )

library( cartogram )  # spatial maps w/ tract size bias reduction
library( maptools )   # spatial object manipulation 
```




## Step 1: Select Your MSA

You can select a city from the list of [large MSAs](https://en.wikipedia.org/wiki/List_of_metropolitan_statistical_areas). 

To get Census data on the city you will first need to identify all of the counties that comprise the MSA. You can look this information up through MSA to FIPS crosswalks provided by the National Bureau for Economic Research (NBER):  https://www.nber.org/data/cbsa-fips-county-crosswalk.html 

I have added the file to GitHub for ease of access. 

```{r}
crosswalk <- read.csv( "https://raw.githubusercontent.com/DS4PS/cpp-529-master/master/data/cbsatocountycrosswalk.csv",  stringsAsFactors=F, colClasses="character" )

# search for citie names by strings, use the ^ anchor for "begins with" 

# grep( "^NEW", crosswalk$msaname, value=TRUE ) 

```


Select all of your county fips. To use them in the TidyCenss package you will need to split the state and county:

```{r}
these.no <- crosswalk$msaname == "NEW ORLEANS, LA"
these.fips <- crosswalk$fipscounty[ these.no ]
these.fips <- na.omit( these.fips )
```


## Step 2: Download a Shapefile with Population Data

To create a Dorling cartogram we need a shapefile and a population count. We can get both through the Census download that includes simple features. 

```{r, echo=F}
key <- "b431c35dad89e2863681311677d12581e8f24c24"
census_api_key( key )
```


```{r}
library( tidycensus )

# census_api_key("YOUR KEY GOES HERE")
# key <- "abc123"
# census_api_key( key )
```


```{r, results='hide'}
these.no <- crosswalk$msaname == "NEW ORLEANS, LA"
these.fips <- crosswalk$fipscounty[ these.no ]
these.fips <- na.omit( these.fips )

state.fips <- substr( these.fips, 1, 2 )
county.fips <- substr( these.fips, 3, 5 )

no.pop <-
get_acs( geography = "tract", variables = "B01003_001",
         state = "22", county = county.fips[state.fips=="22"], geometry = TRUE ) %>% 
         select( GEOID, estimate ) %>%
         rename( POP=estimate )
```


## Step 3: Add Census Data

```{r}
URL <- "https://github.com/DS4PS/cpp-529-master/raw/master/data/ltdb_std_2010_sample.rds"
census.dat <- readRDS(gzcon(url( URL )))

# can merge an sf object and data.frame
no <- merge( no.pop, census.dat, by.x="GEOID", by.y="tractid" )

# make sure there are no empty polygons
no <- no[ ! st_is_empty( no ) , ]
```


**DATA DICTIONARY**


```{r, echo=F}
data.dictionary <- 
structure(list(LABEL = c("tractid", "pnhwht12", "pnhblk12", "phisp12", 
"pntv12", "pfb12", "polang12", "phs12", "pcol12", "punemp12", 
"pflabf12", "pprof12", "pmanuf12", "pvet12", "psemp12", "hinc12", 
"incpc12", "ppov12", "pown12", "pvac12", "pmulti12", "mrent12", 
"mhmval12", "p30old12", "p10yrs12", "p18und12", "p60up12", "p75up12", 
"pmar12", "pwds12", "pfhh12"), VARIABLE = c("GEOID", "Percent white, non-Hispanic", 
"Percent black, non-Hispanic", "Percent Hispanic", "Percent Native American race", 
"Percent foreign born", "Percent speaking other language at home, age 5 plus", 
"Percent with high school degree or less", "Percent with 4-year college degree or more", 
"Percent unemployed", "Percent female labor force participation", 
"Percent professional employees", "Percent manufacturing employees", 
"Percent veteran", "Percent self-employed", "Median HH income, total", 
"Per capita income", "Percent in poverty, total", "Percent owner-occupied units", 
"Percent vacant units", "Percent multi-family units", "Median rent", 
"Median home value", "Percent structures more than 30 years old", 
"Percent HH in neighborhood 10 years or less", "Percent 17 and under, total", 
"Percent 60 and older, total", "Percent 75 and older, total", 
"Percent currently married, not separated", "Percent widowed, divorced and separated", 
"Percent female-headed families with children")), class = "data.frame", row.names = c(NA, 
-31L))

data.dictionary %>% pander()
```






## Step 4: Transform the Shapefile into A Dorling Cartogram

```{r}
# convert sf map object to an sp version
no.sp <- as_Spatial( no )

class( no.sp )

# project map and remove empty tracts
no.sp <- spTransform( no.sp, CRS("+init=epsg:3395"))
no.sp <- no.sp[ no.sp$POP != 0 & (! is.na( no.sp$POP )) , ]

# convert census tract polygons to dorling cartogram
# no idea why k=0.03 works, but it does - default is k=5
no.sp$pop.w <- no.sp$POP / 9000 # max(msp.sp$POP)   # standardizes it to max of 1.5
no_dorling <- cartogram_dorling( x=no.sp, weight="pop.w", k=0.05 )


d1 <- no_dorling@data


```


```{r}
tm_shape( no_dorling ) + 
  tm_polygons( size="POP", col="treatment", n=7, style="quantile", palette="Spectral" )

```


```{r}


tmap_mode("plot")
tmap_style("cobalt")

# user-defined bounding box to move slocer to subjects 
 bb <- st_bbox( c( xmin =  -10451823, xmax = -10324525, 
                  ymax = 5639769, ymin = 5491665 ), 
              crs = st_crs("+init=epsg:3395"))

tm1 <- 
tm_shape( no_dorling, bbox=bb ) + 
  tm_polygons( col="new.dat", palette="Accent"  )



tmap_arrange( tm1)

```
